# Experiment Report

## Header
**Experiment Name**: First Iteration Adaptive Prompt vs Default Prompt \
**Date**: 01.09.2024 

---

## Goal of Experiment
The objective of this experiment is to compare the quality of feedback generated by two different prompts for an LLM. One is a default prompt, which provides only question-related information, and the other is an adaptive prompt that includes detailed contextual data about the student, question, and preferences. The aim is to determine which feedback method is more effective for improving learning outcomes.


---

## Activities
1.	Design of Default and Adaptive Prompts \
The default prompt contains basic question data, while the adaptive prompt includes richer contextual information like student preferences, question-related performance statistics, and option-selection rates.
2.	Selection of Q16 \
The Q16 question was selected as the test case for feedback generation. Both prompts were used to generate feedback on this question for comparison purposes.
3.	Grid Search over Feedback Preferences \
A grid search was conducted over feedback preferences (e.g., tone, length, timeliness) in the adaptive prompt, resulting in 24 unique adaptive feedback outputs. These were compared with 24 generic feedback outputs from the default prompt.
4.	Generation of Feedback for 24 Students \
The feedback was generated for 24 different student profiles using both the default and adaptive prompts. This provided diverse feedback for the same question, tailored to varying contexts.
5.	Comparison of Feedback \
A comparative evaluation of the feedback was conducted by reviewing the quality, relevance, and tone of the generated outputs. Machine evaluation was employed to assess which feedback was superior.

---

## Results
1.	Poor Feedback Quality Overall \
Both methods produced low-quality feedback. The generated responses lacked depth, clarity, and relevance, especially in addressing student misconceptions.
2.	Need for an Evaluation Framework \
It became clear that a framework or rubric is required to define what constitutes “good” feedback. This will guide both human and automated evaluations.
3.	ITS Context Missing in Prompts \
The feedback produced seemed like emails directed to students, which is inappropriate for an Intelligent Tutoring System (ITS) context. The prompt needs to make it clear that the feedback is part of ITS to ensure the right tone and format.

---

## Comments
* Misconceptions Not Addressed \
The model struggles to detect student misconceptions and errors in their answers. Additional information about common mistakes or option-specific lures could help the model generate more targeted feedback.
* Feedback Timeliness Parameter Unnecessary \
The “feedback timeliness” parameter had no effect on the content quality and will be excluded from future experiments.
*  Excessive Praising in Feedback \
The model tends to over-praise the student in its feedback, even when a “direct” tone is requested. A more granular approach to tone-setting may help adjust this behavior.

---

## Todos
- [x] Define Good Feedback: Establish a clear definition and criteria for what makes feedback effective.
- [x] Develop Evaluation Framework: Build a rubric for evaluating feedback quality and automate this process where possible.
- [x] Integrate ITS Context: Modify the prompt to explicitly state that feedback is part of an ITS system to ensure the format and tone are appropriate.
- [x] Generate Stock Feedback Dataset: Run the default prompt for all questions in the dataset and save the results for future comparison.
- [ ] Refine Adaptive Prompt: Improve the adaptive prompt by adding information about student misconceptions and option-specific lures. (Experiment 3)
- [x] Improve Tone Control: Continue refining the tone and praise balance in feedback.
- [x] Plan Future Iterations: Drop the timeliness parameter and conduct further experiments to improve feedback quality.
- [ ] Human Evaluation: Send feedback to experts for evaluation and compare machine and human evaluations at a later stage. (Evaluation)
